{"cells":[{"cell_type":"code","source":["%%capture\n","\n","!pip install -q pyspark findspark\n","\n","import findspark\n","findspark.init()\n","\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"],"metadata":{"id":"DOxc_eyVigJp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git clone https://github.com/javieraespinosa/big-data-analytics-practicals\n","!mv big-data-analytics-practicals/data/* .\n","!ls *.csv"],"metadata":{"id":"JS8WnRm8ii2S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sc = spark.sparkContext\n","sc"],"metadata":{"id":"z74cxzrcilHG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kjpjW8Z6ieqe"},"source":["# TP RDD"]},{"cell_type":"markdown","metadata":{"id":"sZOnlEYgieqi"},"source":["Dans cet atelier, nous allons explorer certains les concepts de RDD que nous avons abordés. Nous utiliserons un ensemble de données comprenant les crimes signalés à Washington, du 3 octobre 2015 au 2 octobre 2016. Ces données proviennent du catalogue de données ouvertes du district de Columbia. Nous utiliserons ces données pour explorer certaines transformations et actions sur les RDD et les pairs RDD.\n","https://github.com/frankieliu/databricks2/blob/master/wash_dc_crime_incidents_2013.csv"]},{"cell_type":"markdown","metadata":{"id":"ox24_iRYieqj"},"source":["Nous pouvons à présent commencer le TP."]},{"cell_type":"markdown","metadata":{"id":"bAKSiSJhieqo"},"source":["## Créer un RDD"]},{"cell_type":"markdown","metadata":{"id":"WxWm0Gq_ieqp"},"source":["La première étape consiste à charger les données.\n","Exécutez la cellule suivante pour créer un RDD contenant les données."]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"6tKpONXfieqp"},"outputs":[],"source":["myRdd =  sc.textFile(\"wash_dc_crime_incidents_2013.csv\")"]},{"cell_type":"markdown","metadata":{"id":"wT9GIDtgieqp"},"source":["La lecture d'un fichier n'est pas une action et par conséquent aucun traitement sera effectué.\n","\n","Comptez le nombre de ligne contenu dans le RDD `myRDD` :"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YFuXBOlOieqq"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"Gm41BNj2ieqq"},"source":["## Exploration des données"]},{"cell_type":"markdown","metadata":{"id":"1FDij55dieqq"},"source":["Voyons quelques-unes des données."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pt3jOEpeieqq"},"outputs":[],"source":["# Affichez les 5 premières lignes du RDD \"myRdd\"\n"]},{"cell_type":"markdown","metadata":{"id":"fW9ZrwdEieqr"},"source":["Super, comme vous pouvez le constater il y a un en-tête.\n","Cet en-tête est fourni au début du fichier, cela signifie qu'une seul partition disposera de l'en-tête.\n","Pour effectuer un traitement homogène sur l'ensemble des données, nous devrons vérifier si le bloc en cours de traitement a un en-tête.\n","Quand le fichier taille des Go voir de To de données, cette vérification peut vite devenir coûteuse, c'est pourquoi on préfère traiter les données sans en-tête.\n","\n","Trouvez une solution pour supprimer l'en-tête :\n","\n","Indice: utilisez la method filter de l'API RDD.\n","\n","https://spark.apache.org/docs/latest/api/python/pyspark.html?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OpDeWqhZieqr"},"outputs":[],"source":["# indiquer le traitement à effectuer pour supprimer l'en-tête\n","# nous appelerons le RDD sans en-tête \"noHeaderRdd\"\n"]},{"cell_type":"markdown","metadata":{"id":"mG1VNlK6ieqr"},"source":["Sauvegarder les données sans l'entête sous le nom de fichier wash_dc_crime_incidents_2013_without_header.csv"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bs5Sp_tfieqr"},"outputs":[],"source":["noHeaderRdd.saveAsTextFile('wash_dc_crime_incidents_2013_without_header.csv')"]},{"cell_type":"markdown","metadata":{"id":"LICvWhE_ieqs"},"source":["A partir du fichier sans entête, découper les lignes en cellules individuelles.\n","\n","Nous appelerons le RDD resultant de cette transformation \"CrimeData\".\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a0MJp95kieqs"},"outputs":[],"source":["# Complétez le code\n"]},{"cell_type":"markdown","metadata":{"id":"zWyPJs4Dieqs"},"source":["La réprésentation des données laisse à désirer sans la schéma des données.\n","En python, on peut associer des noms à chaque valeur du tuple avec le module namedtuple :"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GkuBKJPYieqt"},"outputs":[],"source":["from collections import namedtuple\n","\n","CrimeDataTuple = namedtuple('CrimeData', ['date_string', 'time_string', 'offense', 'latitude', 'longitude'])\n","\n","def map_line(line):\n","  cols = line.split(\",\")\n","  return CrimeDataTuple(date_string=cols[10], time_string=cols[11], offense=cols[3], latitude=cols[7], longitude=cols[8])\n","\n","CrimeDataT = noHeaderRdd.map(map_line)\n","\n","CrimeDataT.take(10)"]},{"cell_type":"markdown","metadata":{"id":"YhdUTncdiequ"},"source":["On obtient une liste de tuple plus lisible.\n","\n","A présent, regroupez les données par type de crime (OFFENSE)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j5750SBOiequ"},"outputs":[],"source":["# Nous utiliserons la methode groupBY\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ldcan1oYieqv"},"outputs":[],"source":["#Affichez les 5 premiers éléments :\n"]},{"cell_type":"markdown","metadata":{"id":"3PZLta4sieqv"},"source":["Ensuite, créez un RDD qui compte le nombre de chaque infraction (OFFENSE)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gHqE7-lCieqw"},"outputs":[],"source":["#Indice : utilisez la méthode map sur le RDD pair obtenu précédement avec la function len\n"]},{"cell_type":"markdown","metadata":{"id":"Ja16zEgHieqw"},"source":["A partir du RDD CrimeDataT, répéter l'opération de comptage des OFFENSES avec la méthode RDD groupByKey :"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r62PKxgzieqx"},"outputs":[],"source":["#Indice : utilisez la méthode map sur le RDD pair obtenu précédement avec la function len\n"]},{"cell_type":"markdown","metadata":{"id":"EU_YvUC5ieqx"},"source":["Combien de meurtres (homicide) y a-t-il eu pendant la période couverte par les données?\n","\n","Attention votre traitement devra être insensible à la casse"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4VIBNNTjieqy"},"outputs":[],"source":["# utilisez le RDD CrimeDataT pour compter le nombre d'homicide\n","# votre traitement devra être insensible à la maniére dont est ecrit homicide\n","# Vous devrez utiliser effectuer le comptage avec la méthode reduceByKey\n","# Vous afficherez le résultat de votre RDD homicide_count\n"]},{"cell_type":"markdown","metadata":{"id":"eugjZBGpieqz"},"source":["Affichez le top 5 des crimes :"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"91GGxmRMieqz"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"V3SN9Fycieqz"},"source":["Vous pouvez à présent fermer le SparkContext."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VRFMx0Rgieqz"},"outputs":[],"source":["sc.stop()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lI6CJLVMieq0"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}